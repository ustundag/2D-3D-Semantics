{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python368-64\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['mat', 'time']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import os\n",
    "import keras\n",
    "import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "import glob\n",
    "from scipy.io import loadmat \n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from time import time\n",
    "\n",
    "from keras import callbacks\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Input, Dense, Dropout, Conv2D, MaxPool2D, UpSampling2D, Activation\n",
    "from keras.initializers import VarianceScaling\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import normalized_mutual_info_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find actual cluster types and ground truth labels. E.g. Area3 has 6 different rooms as follows;\n",
    "\n",
    "{'WC', 'conferenceRoom', 'hallway', 'lounge', 'office', 'storage'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ground_truth_clusters_and_labels():\n",
    "    path = \"C:\\\\Users\\\\ustundag\\\\GitHub\\\\2D-3D-Semantics\\\\area_3\\\\data\\\\semantic\\\\*.png\"\n",
    "    labels = []\n",
    "\n",
    "    for path in glob.glob(path):\n",
    "        s = path.split('_')\n",
    "        room = s[3]\n",
    "        labels.append(str(room))\n",
    "    \n",
    "    labels = [l.replace('WC'            , '0') for l in labels]\n",
    "    labels = [l.replace('conferenceRoom', '1') for l in labels]\n",
    "    labels = [l.replace('hallway'       , '2') for l in labels]\n",
    "    labels = [l.replace('lounge'        , '3') for l in labels]\n",
    "    labels = [l.replace('office'        , '4') for l in labels]\n",
    "    labels = [l.replace('storage'       , '5') for l in labels]\n",
    "\n",
    "    return np.asarray(list(map(int, labels)), dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_room_type(i):\n",
    "    if i == 0: return 'WC'\n",
    "    if i == 1: return 'conferenceRoom'\n",
    "    if i == 2: return 'hallway'\n",
    "    if i == 3: return 'lounge'\n",
    "    if i == 4: return 'office'\n",
    "    if i == 5: return 'storage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = loadmat(\"C:\\\\Users\\\\ustundag\\\\GitHub\\\\2D-3D-Semantics\\\\noXYZ_area_3_no_xyz_data_semantic_90x90.mat\")\n",
    "images = mat[\"semantic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign ground truth labels\n",
    "labels_gt = find_ground_truth_clusters_and_labels()\n",
    "# Split dataset into tarin and test\n",
    "x_train = images[:3000] / 255.0\n",
    "x_test  = images[-704:] / 255.0\n",
    "y_train = labels_gt[:3000]\n",
    "y_test  = labels_gt[-704:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To stop potential randomness\n",
    "seed = 128\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Room type: lounge\n"
     ]
    }
   ],
   "source": [
    "i = 123\n",
    "pylab.imshow(x_test[i].reshape(90, 90), cmap='gray')\n",
    "pylab.show()\n",
    "print('Room type: ' + str(get_room_type(y_test[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans Beasic Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_jobs=-1, n_clusters = 6, n_init=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=6, n_init=20, n_jobs=-1, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = km.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python368-64\\lib\\site-packages\\sklearn\\metrics\\cluster\\supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10246013146085442"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_mutual_info_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder + KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\python368-64\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 8100)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               4050500   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2000)              1002000   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                20010     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2000)              22000     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 500)               1000500   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8100)              4058100   \n",
      "=================================================================\n",
      "Total params: 10,654,110\n",
      "Trainable params: 10,654,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# this is our input placeholder\n",
    "input_img = Input(shape=(8100,))\n",
    "\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(500, activation='relu')(input_img)\n",
    "encoded = Dense(500, activation='relu')(encoded)\n",
    "encoded = Dense(2000, activation='relu')(encoded)\n",
    "encoded = Dense(10, activation='sigmoid')(encoded)\n",
    "\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(2000, activation='relu')(encoded)\n",
    "decoded = Dense(500, activation='relu')(decoded)\n",
    "decoded = Dense(500, activation='relu')(decoded)\n",
    "decoded = Dense(8100)(decoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\python368-64\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 3000 samples, validate on 704 samples\n",
      "Epoch 1/50\n",
      "3000/3000 [==============================] - 14s 5ms/step - loss: 1.4957e-06 - val_loss: 2.7943e-08\n",
      "Epoch 2/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.0522e-08 - val_loss: 2.7513e-08\n",
      "Epoch 3/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.0503e-08 - val_loss: 2.7785e-08\n",
      "Epoch 4/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.0578e-08 - val_loss: 2.7805e-08\n",
      "Epoch 5/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.0631e-08 - val_loss: 2.8105e-08\n",
      "Epoch 6/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.0703e-08 - val_loss: 2.8214e-08\n",
      "Epoch 7/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.0680e-08 - val_loss: 2.7643e-08\n",
      "Epoch 8/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.0780e-08 - val_loss: 2.7821e-08\n",
      "Epoch 9/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.0765e-08 - val_loss: 2.8201e-08\n",
      "Epoch 10/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.0892e-08 - val_loss: 2.8054e-08\n",
      "Epoch 11/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.0939e-08 - val_loss: 2.8648e-08\n",
      "Epoch 12/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.0927e-08 - val_loss: 2.7988e-08\n",
      "Epoch 13/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1087e-08 - val_loss: 2.8024e-08\n",
      "Epoch 14/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1102e-08 - val_loss: 2.8423e-08\n",
      "Epoch 15/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1035e-08 - val_loss: 2.8057e-08\n",
      "Epoch 16/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.0989e-08 - val_loss: 2.8190e-08\n",
      "Epoch 17/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.0899e-08 - val_loss: 2.8026e-08\n",
      "Epoch 18/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.0966e-08 - val_loss: 2.7767e-08\n",
      "Epoch 19/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.0967e-08 - val_loss: 2.8059e-08\n",
      "Epoch 20/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1009e-08 - val_loss: 2.8142e-08\n",
      "Epoch 21/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1158e-08 - val_loss: 2.8107e-08\n",
      "Epoch 22/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1204e-08 - val_loss: 2.9046e-08\n",
      "Epoch 23/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1068e-08 - val_loss: 2.8888e-08\n",
      "Epoch 24/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1228e-08 - val_loss: 2.8254e-08\n",
      "Epoch 25/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1085e-08 - val_loss: 2.8237e-08\n",
      "Epoch 26/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1110e-08 - val_loss: 2.8196e-08\n",
      "Epoch 27/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1239e-08 - val_loss: 2.7966e-08\n",
      "Epoch 28/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1101e-08 - val_loss: 2.8506e-08\n",
      "Epoch 29/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1337e-08 - val_loss: 2.8818e-08\n",
      "Epoch 30/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1072e-08 - val_loss: 2.8355e-08\n",
      "Epoch 31/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1368e-08 - val_loss: 2.8096e-08\n",
      "Epoch 32/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1149e-08 - val_loss: 2.8616e-08\n",
      "Epoch 33/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1278e-08 - val_loss: 2.7988e-08\n",
      "Epoch 34/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1228e-08 - val_loss: 2.8428e-08\n",
      "Epoch 35/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1310e-08 - val_loss: 2.8089e-08\n",
      "Epoch 36/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1373e-08 - val_loss: 2.8467e-08\n",
      "Epoch 37/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1264e-08 - val_loss: 2.8228e-08\n",
      "Epoch 38/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1318e-08 - val_loss: 2.8528e-08\n",
      "Epoch 39/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1303e-08 - val_loss: 2.8080e-08\n",
      "Epoch 40/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1229e-08 - val_loss: 2.8050e-08\n",
      "Epoch 41/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1329e-08 - val_loss: 2.8329e-08\n",
      "Epoch 42/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1217e-08 - val_loss: 2.8086e-08\n",
      "Epoch 43/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1186e-08 - val_loss: 2.8231e-08\n",
      "Epoch 44/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1206e-08 - val_loss: 2.9054e-08\n",
      "Epoch 45/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1265e-08 - val_loss: 2.8163e-08\n",
      "Epoch 46/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1509e-08 - val_loss: 2.8782e-08\n",
      "Epoch 47/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1326e-08 - val_loss: 2.8804e-08\n",
      "Epoch 48/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1609e-08 - val_loss: 2.8764e-08\n",
      "Epoch 49/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1193e-08 - val_loss: 2.7943e-08\n",
      "Epoch 50/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1392e-08 - val_loss: 2.8196e-08\n"
     ]
    }
   ],
   "source": [
    "train_history = autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=32,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_auto_train = encoder.predict(x_train)\n",
    "pred_auto = encoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "km.fit(pred_auto_train)\n",
    "pred = km.predict(pred_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python368-64\\lib\\site-packages\\sklearn\\metrics\\cluster\\supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1190445406885029"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_mutual_info_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras implementation for Deep Embedded Clustering (DEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras import callbacks\n",
    "from keras.initializers import VarianceScaling\n",
    "from sklearn.cluster import KMeans\n",
    "import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Pretraining...\n",
      "Epoch 1/50\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 3.9615e-08\n",
      "        |==>  acc: 0.3080,  nmi: 0.1041  <==|\n",
      "Epoch 2/50\n",
      "  64/3000 [..............................] - ETA: 6s - loss: 3.1023e-08"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python368-64\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:21: DeprecationWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  DeprecationWarning)\n",
      "c:\\python368-64\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  DeprecationWarning)\n",
      "c:\\python368-64\\lib\\site-packages\\sklearn\\metrics\\cluster\\supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.0691e-08\n",
      "Epoch 3/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.0727e-08\n",
      "Epoch 4/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.0822e-08\n",
      "Epoch 5/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.0866e-08\n",
      "Epoch 6/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.0939e-08\n",
      "        |==>  acc: 0.3390,  nmi: 0.1278  <==|\n",
      "Epoch 7/50\n",
      "  64/3000 [..............................] - ETA: 6s - loss: 2.8497e-08"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python368-64\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  DeprecationWarning)\n",
      "c:\\python368-64\\lib\\site-packages\\sklearn\\metrics\\cluster\\supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.0939e-08\n",
      "Epoch 8/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1001e-08\n",
      "Epoch 9/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1037e-08\n",
      "Epoch 10/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1264e-08\n",
      "Epoch 11/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1108e-08\n",
      "        |==>  acc: 0.3390,  nmi: 0.1234  <==|\n",
      "Epoch 12/50\n",
      "  64/3000 [..............................] - ETA: 6s - loss: 2.9412e-08"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python368-64\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  DeprecationWarning)\n",
      "c:\\python368-64\\lib\\site-packages\\sklearn\\metrics\\cluster\\supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1063e-08\n",
      "Epoch 13/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1221e-08\n",
      "Epoch 14/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1137e-08\n",
      "Epoch 15/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1127e-08\n",
      "Epoch 16/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1237e-08\n",
      "        |==>  acc: 0.3457,  nmi: 0.1225  <==|\n",
      "Epoch 17/50\n",
      "  64/3000 [..............................] - ETA: 6s - loss: 3.5075e-08"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python368-64\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  DeprecationWarning)\n",
      "c:\\python368-64\\lib\\site-packages\\sklearn\\metrics\\cluster\\supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1228e-08\n",
      "Epoch 18/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1273e-08\n",
      "Epoch 19/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1532e-08\n",
      "Epoch 20/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1400e-08\n",
      "Epoch 21/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1366e-08\n",
      "        |==>  acc: 0.3363,  nmi: 0.1247  <==|\n",
      "Epoch 22/50\n",
      "  64/3000 [..............................] - ETA: 6s - loss: 2.8872e-08"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python368-64\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  DeprecationWarning)\n",
      "c:\\python368-64\\lib\\site-packages\\sklearn\\metrics\\cluster\\supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1420e-08\n",
      "Epoch 23/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1141e-08\n",
      "Epoch 24/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1237e-08\n",
      "Epoch 25/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1194e-08\n",
      "Epoch 26/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1103e-08\n",
      "        |==>  acc: 0.3413,  nmi: 0.1186  <==|\n",
      "Epoch 27/50\n",
      "  64/3000 [..............................] - ETA: 6s - loss: 2.8707e-08"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python368-64\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  DeprecationWarning)\n",
      "c:\\python368-64\\lib\\site-packages\\sklearn\\metrics\\cluster\\supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1508e-08\n",
      "Epoch 28/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1307e-08\n",
      "Epoch 29/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1390e-08\n",
      "Epoch 30/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1213e-08\n",
      "Epoch 31/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1314e-08\n",
      "        |==>  acc: 0.3427,  nmi: 0.1214  <==|\n",
      "Epoch 32/50\n",
      "  64/3000 [..............................] - ETA: 6s - loss: 2.9426e-08"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python368-64\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  DeprecationWarning)\n",
      "c:\\python368-64\\lib\\site-packages\\sklearn\\metrics\\cluster\\supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1216e-08\n",
      "Epoch 33/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1174e-08\n",
      "Epoch 34/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1210e-08\n",
      "Epoch 35/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1187e-08\n",
      "Epoch 36/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1373e-08\n",
      "        |==>  acc: 0.3413,  nmi: 0.1185  <==|\n",
      "Epoch 37/50\n",
      "  64/3000 [..............................] - ETA: 6s - loss: 3.3788e-08"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python368-64\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  DeprecationWarning)\n",
      "c:\\python368-64\\lib\\site-packages\\sklearn\\metrics\\cluster\\supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1257e-08\n",
      "Epoch 38/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1257e-08\n",
      "Epoch 39/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1258e-08\n",
      "Epoch 40/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1292e-08\n",
      "Epoch 41/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1603e-08\n",
      "        |==>  acc: 0.3417,  nmi: 0.1184  <==|\n",
      "Epoch 42/50\n",
      "  64/3000 [..............................] - ETA: 6s - loss: 3.0830e-08"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python368-64\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  DeprecationWarning)\n",
      "c:\\python368-64\\lib\\site-packages\\sklearn\\metrics\\cluster\\supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1257e-08\n",
      "Epoch 43/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1441e-08\n",
      "Epoch 44/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1434e-08\n",
      "Epoch 45/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1563e-08\n",
      "Epoch 46/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1300e-08\n",
      "        |==>  acc: 0.3413,  nmi: 0.1203  <==|\n",
      "Epoch 47/50\n",
      "  64/3000 [..............................] - ETA: 6s - loss: 3.0739e-08"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python368-64\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  DeprecationWarning)\n",
      "c:\\python368-64\\lib\\site-packages\\sklearn\\metrics\\cluster\\supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1335e-08\n",
      "Epoch 48/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1424e-08\n",
      "Epoch 49/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1363e-08\n",
      "Epoch 50/50\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 3.1634e-08\n",
      "Pretraining time:  363.8118462562561\n",
      "Pretrained weights are saved to results/ae_weights.h5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Keras implementation for Deep Embedded Clustering (DEC) algorithm:\n",
    "\n",
    "Original Author:\n",
    "    Xifeng Guo. 2017.1.30\n",
    "\"\"\"\n",
    "\n",
    "def autoencoder(dims, act='relu', init='glorot_uniform'):\n",
    "    \"\"\"\n",
    "    Fully connected auto-encoder model, symmetric.\n",
    "    Arguments:\n",
    "        dims: list of number of units in each layer of encoder. dims[0] is input dim, dims[-1] is units in hidden layer.\n",
    "            The decoder is symmetric with encoder. So number of layers of the auto-encoder is 2*len(dims)-1\n",
    "        act: activation, not applied to Input, Hidden and Output layers\n",
    "    return:\n",
    "        (ae_model, encoder_model), Model of autoencoder and model of encoder\n",
    "    \"\"\"\n",
    "    n_stacks = len(dims) - 1\n",
    "    # input\n",
    "    x = Input(shape=(dims[0],), name='input')\n",
    "    h = x\n",
    "\n",
    "    # internal layers in encoder\n",
    "    for i in range(n_stacks-1):\n",
    "        h = Dense(dims[i + 1], activation=act, kernel_initializer=init, name='encoder_%d' % i)(h)\n",
    "\n",
    "    # hidden layer\n",
    "    h = Dense(dims[-1], kernel_initializer=init, name='encoder_%d' % (n_stacks - 1))(h)  # hidden layer, features are extracted from here\n",
    "\n",
    "    y = h\n",
    "    # internal layers in decoder\n",
    "    for i in range(n_stacks-1, 0, -1):\n",
    "        y = Dense(dims[i], activation=act, kernel_initializer=init, name='decoder_%d' % i)(y)\n",
    "\n",
    "    # output\n",
    "    y = Dense(dims[0], kernel_initializer=init, name='decoder_0')(y)\n",
    "\n",
    "    return Model(inputs=x, outputs=y, name='AE'), Model(inputs=x, outputs=h, name='encoder')\n",
    "\n",
    "\n",
    "class ClusteringLayer(Layer):\n",
    "    \"\"\"\n",
    "    Clustering layer converts input sample (feature) to soft label, i.e. a vector that represents the probability of the\n",
    "    sample belonging to each cluster. The probability is calculated with student's t-distribution.\n",
    "\n",
    "    # Example\n",
    "    ```\n",
    "        model.add(ClusteringLayer(n_clusters=6))\n",
    "    ```\n",
    "    # Arguments\n",
    "        n_clusters: number of clusters.\n",
    "        weights: list of Numpy array with shape `(n_clusters, n_features)` witch represents the initial cluster centers.\n",
    "        alpha: parameter in Student's t-distribution. Default to 1.0.\n",
    "    # Input shape\n",
    "        2D tensor with shape: `(n_samples, n_features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(n_samples, n_clusters)`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_clusters, weights=None, alpha=1.0, **kwargs):\n",
    "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
    "            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
    "        super(ClusteringLayer, self).__init__(**kwargs)\n",
    "        self.n_clusters = n_clusters\n",
    "        self.alpha = alpha\n",
    "        self.initial_weights = weights\n",
    "        self.input_spec = InputSpec(ndim=2)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 2\n",
    "        input_dim = input_shape[1]\n",
    "        self.input_spec = InputSpec(dtype=K.floatx(), shape=(None, input_dim))\n",
    "        self.clusters = self.add_weight((self.n_clusters, input_dim), initializer='glorot_uniform', name='clusters')\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        \"\"\" student t-distribution, as same as used in t-SNE algorithm.\n",
    "                 q_ij = 1/(1+dist(x_i, u_j)^2), then normalize it.\n",
    "        Arguments:\n",
    "            inputs: the variable containing data, shape=(n_samples, n_features)\n",
    "        Return:\n",
    "            q: student's t-distribution, or soft labels for each sample. shape=(n_samples, n_clusters)\n",
    "        \"\"\"\n",
    "        q = 1.0 / (1.0 + (K.sum(K.square(K.expand_dims(inputs, axis=1) - self.clusters), axis=2) / self.alpha))\n",
    "        q **= (self.alpha + 1.0) / 2.0\n",
    "        q = K.transpose(K.transpose(q) / K.sum(q, axis=1))\n",
    "        return q\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape and len(input_shape) == 2\n",
    "        return input_shape[0], self.n_clusters\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'n_clusters': self.n_clusters}\n",
    "        base_config = super(ClusteringLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class DEC(object):\n",
    "    def __init__(self,\n",
    "                 dims,\n",
    "                 n_clusters=6,\n",
    "                 alpha=1.0,\n",
    "                 init='glorot_uniform'):\n",
    "\n",
    "        super(DEC, self).__init__()\n",
    "\n",
    "        self.dims = dims\n",
    "        self.input_dim = dims[0]\n",
    "        self.n_stacks = len(self.dims) - 1\n",
    "\n",
    "        self.n_clusters = n_clusters\n",
    "        self.alpha = alpha\n",
    "        self.autoencoder, self.encoder = autoencoder(self.dims, init=init)\n",
    "\n",
    "        # prepare DEC model\n",
    "        clustering_layer = ClusteringLayer(self.n_clusters, name='clustering')(self.encoder.output)\n",
    "        self.model = Model(inputs=self.encoder.input, outputs=clustering_layer)\n",
    "\n",
    "    def pretrain(self, x, y=None, optimizer='adam', epochs=200, batch_size=256, save_dir='results/temp'):\n",
    "        print('...Pretraining...')\n",
    "        self.autoencoder.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "        csv_logger = callbacks.CSVLogger(save_dir + '/pretrain_log.csv')\n",
    "        cb = [csv_logger]\n",
    "        if y is not None:\n",
    "            class PrintACC(callbacks.Callback):\n",
    "                def __init__(self, x, y):\n",
    "                    self.x = x\n",
    "                    self.y = y\n",
    "                    super(PrintACC, self).__init__()\n",
    "\n",
    "                def on_epoch_end(self, epoch, logs=None):\n",
    "                    if epoch % int(epochs/10) != 0:\n",
    "                        return\n",
    "                    feature_model = Model(self.model.input,\n",
    "                                          self.model.get_layer(\n",
    "                                              'encoder_%d' % (int(len(self.model.layers) / 2) - 1)).output)\n",
    "                    features = feature_model.predict(self.x)\n",
    "                    km = KMeans(n_clusters=len(np.unique(self.y)), n_init=20, n_jobs=4)\n",
    "                    y_pred = km.fit_predict(features)\n",
    "                    # print()\n",
    "                    print(' '*8 + '|==>  acc: %.4f,  nmi: %.4f  <==|'\n",
    "                          % (metrics.acc(self.y, y_pred), metrics.nmi(self.y, y_pred)))\n",
    "\n",
    "            cb.append(PrintACC(x, y))\n",
    "\n",
    "        # begin pretraining\n",
    "        t0 = time()\n",
    "        self.autoencoder.fit(x, x, batch_size=batch_size, epochs=epochs, callbacks=cb)\n",
    "        print('Pretraining time: ', time() - t0)\n",
    "        self.autoencoder.save_weights(save_dir + '/ae_weights.h5')\n",
    "        print('Pretrained weights are saved to %s/ae_weights.h5' % save_dir)\n",
    "        self.pretrained = True\n",
    "\n",
    "    def load_weights(self, weights):  # load weights of DEC model\n",
    "        self.model.load_weights(weights)\n",
    "\n",
    "    def extract_features(self, x):\n",
    "        return self.encoder.predict(x)\n",
    "\n",
    "    def predict(self, x):  # predict cluster labels using the output of clustering layer\n",
    "        q = self.model.predict(x, verbose=0)\n",
    "        return q.argmax(1)\n",
    "\n",
    "    @staticmethod\n",
    "    def target_distribution(q):\n",
    "        weight = q ** 2 / q.sum(0)\n",
    "        return (weight.T / weight.sum(1)).T\n",
    "\n",
    "    def compile(self, optimizer='sgd', loss='kld'):\n",
    "        self.model.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "    def fit(self, x, y=None, maxiter=2e4, batch_size=256, tol=1e-3,\n",
    "            update_interval=140, save_dir='./results/temp'):\n",
    "\n",
    "        print('Update interval', update_interval)\n",
    "        save_interval = x.shape[0] / batch_size * 5  # 5 epochs\n",
    "        print('Save interval', save_interval)\n",
    "\n",
    "        # Step 1: initialize cluster centers using k-means\n",
    "        t1 = time()\n",
    "        print('Initializing cluster centers with k-means.')\n",
    "        kmeans = KMeans(n_clusters=self.n_clusters, n_init=20)\n",
    "        y_pred = kmeans.fit_predict(self.encoder.predict(x))\n",
    "        y_pred_last = np.copy(y_pred)\n",
    "        self.model.get_layer(name='clustering').set_weights([kmeans.cluster_centers_])\n",
    "\n",
    "        # Step 2: deep clustering\n",
    "        # logging file\n",
    "        import csv\n",
    "        logfile = open(save_dir + '/dec_log.csv', 'w')\n",
    "        logwriter = csv.DictWriter(logfile, fieldnames=['iter', 'acc', 'nmi', 'ari', 'loss'])\n",
    "        logwriter.writeheader()\n",
    "\n",
    "        loss = 0\n",
    "        index = 0\n",
    "        index_array = np.arange(x.shape[0])\n",
    "        for ite in range(int(maxiter)):\n",
    "            if ite % update_interval == 0:\n",
    "                q = self.model.predict(x, verbose=0)\n",
    "                p = self.target_distribution(q)  # update the auxiliary target distribution p\n",
    "\n",
    "                # evaluate the clustering performance\n",
    "                y_pred = q.argmax(1)\n",
    "                if y is not None:\n",
    "                    acc = np.round(metrics.acc(y, y_pred), 5)\n",
    "                    nmi = np.round(metrics.nmi(y, y_pred), 5)\n",
    "                    ari = np.round(metrics.ari(y, y_pred), 5)\n",
    "                    loss = np.round(loss, 5)\n",
    "                    logdict = dict(iter=ite, acc=acc, nmi=nmi, ari=ari, loss=loss)\n",
    "                    logwriter.writerow(logdict)\n",
    "                    print('Iter %d: acc = %.5f, nmi = %.5f, ari = %.5f' % (ite, acc, nmi, ari), ' ; loss=', loss)\n",
    "\n",
    "                # check stop criterion\n",
    "                delta_label = np.sum(y_pred != y_pred_last).astype(np.float32) / y_pred.shape[0]\n",
    "                y_pred_last = np.copy(y_pred)\n",
    "                if ite > 0 and delta_label < tol:\n",
    "                    print('delta_label ', delta_label, '< tol ', tol)\n",
    "                    print('Reached tolerance threshold. Stopping training.')\n",
    "                    logfile.close()\n",
    "                    break\n",
    "\n",
    "            # train on batch\n",
    "            # if index == 0:\n",
    "            #     np.random.shuffle(index_array)\n",
    "            idx = index_array[index * batch_size: min((index+1) * batch_size, x.shape[0])]\n",
    "            self.model.train_on_batch(x=x[idx], y=p[idx])\n",
    "            index = index + 1 if (index + 1) * batch_size <= x.shape[0] else 0\n",
    "\n",
    "            # save intermediate model\n",
    "            if ite % save_interval == 0:\n",
    "                print('saving model to:', save_dir + '/DEC_model_' + str(ite) + '.h5')\n",
    "                self.model.save_weights(save_dir + '/DEC_model_' + str(ite) + '.h5')\n",
    "\n",
    "            ite += 1\n",
    "\n",
    "        # save the trained model\n",
    "        logfile.close()\n",
    "        print('saving model to:', save_dir + '/DEC_model_final.h5')\n",
    "        self.model.save_weights(save_dir + '/DEC_model_final.h5')\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# setting the hyper parameters\n",
    "init = 'glorot_uniform'\n",
    "pretrain_optimizer = 'adam'\n",
    "dataset = 'mnist'\n",
    "batch_size = 32\n",
    "maxiter = 2e4\n",
    "tol = 0.001\n",
    "save_dir = 'results'\n",
    "\n",
    "import os\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "update_interval = 200\n",
    "pretrain_epochs = 50\n",
    "init = VarianceScaling(scale=1. / 3., mode='fan_in',\n",
    "                       distribution='uniform')  # [-limit, limit], limit=sqrt(1./fan_in)\n",
    "#pretrain_optimizer = SGD(lr=1, momentum=0.9)\n",
    "\n",
    "\n",
    "# prepare the DEC model\n",
    "dec = DEC(dims=[x_train.shape[-1], 500, 500, 2000, 10], n_clusters=6, init=init)\n",
    "\n",
    "dec.pretrain(x=x_train, y=y_train, optimizer=pretrain_optimizer,\n",
    "             epochs=pretrain_epochs, batch_size=batch_size,\n",
    "             save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 8100)              0         \n",
      "_________________________________________________________________\n",
      "encoder_0 (Dense)            (None, 500)               4050500   \n",
      "_________________________________________________________________\n",
      "encoder_1 (Dense)            (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "encoder_2 (Dense)            (None, 2000)              1002000   \n",
      "_________________________________________________________________\n",
      "encoder_3 (Dense)            (None, 10)                20010     \n",
      "_________________________________________________________________\n",
      "clustering (ClusteringLayer) (None, 6)                 60        \n",
      "=================================================================\n",
      "Total params: 5,323,070\n",
      "Trainable params: 5,323,070\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dec.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.compile(optimizer=SGD(0.01, 0.9), loss='kld')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update interval 200\n",
      "Save interval 468.75\n",
      "Initializing cluster centers with k-means.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python368-64\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  DeprecationWarning)\n",
      "c:\\python368-64\\lib\\site-packages\\sklearn\\metrics\\cluster\\supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: acc = 0.36767, nmi = 0.08961, ari = 0.00169  ; loss= 0\n",
      "saving model to: results/DEC_model_0.h5\n",
      "Iter 200: acc = 0.36767, nmi = 0.08961, ari = 0.00169  ; loss= 0\n",
      "delta_label  0.0 < tol  0.001\n",
      "Reached tolerance threshold. Stopping training.\n",
      "saving model to: results/DEC_model_final.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python368-64\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  DeprecationWarning)\n",
      "c:\\python368-64\\lib\\site-packages\\sklearn\\metrics\\cluster\\supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "y_pred = dec.fit(x_train, y=y_train, tol=tol, maxiter=maxiter, batch_size=batch_size,\n",
    "                 update_interval=update_interval, save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = dec.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 5}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python368-64\\lib\\site-packages\\sklearn\\metrics\\cluster\\supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08507417631224175"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_mutual_info_score(y_test, pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
